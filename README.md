# SPARK FUNDAMENTALS

This is a summary of my studies to the Spark Associate Developer for Apache Spark 3.0, the requirements [are](https://academy.databricks.com/exam/databricks-certified-associate-developer):

- have a basic understanding of the Spark architecture, including Adaptive Query Execution
- be able to apply the Spark DataFrame API to complete individual data manipulation task, including: 
  - selecting, renaming and manipulating columns
  - filtering, dropping, sorting, and aggregating rows
  - joining, reading, writing and partitioning DataFrames
  - working with UDFs and Spark SQL functions
 
## Spark arquitecture

## DataFrame API
 
 
### Selecting, renaming and manipulating columns:




## Filtering, dropping, sorting, and aggregating rows

- Aggregate functions
- Sorting functions
- String functions 

## joining, reading, writing and partitioning DataFrames
 
 
## working with UDFs and Spark SQL functions
  
  
## Other functions

- Collection functions
- Datetime functions
- Math functions
- Miscellaneous functions
- Non-aggregate functions
